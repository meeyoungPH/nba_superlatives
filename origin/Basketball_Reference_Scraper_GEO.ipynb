{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import unidecode\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Output Folder Data Path\n",
    "path = \"output_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = ['AO','AG','AR','AU','AT','BS','BE','BA','BR','BG','CM','CA','CV','CN','CO',\n",
    "        'HR','CU','CZ','CD','DK','DM','DO','EG','EE','FI','FR','GF','GA','GE','DE',\n",
    "        'GH','GR','GP','GN','GY','HT','HU','IS','IE','IR','IL','IT','JM','JP','LV','LB',\n",
    "        'LT','LU','ML','MQ','MX','ME','MA','NL','NZ','NG','NO','PA','PL','PT','PR','KR','MK',\n",
    "        'CG','RO','RU','LC','VC','SN','RS','SK','SI','ZA','SS','ES','SD','SE','CH','TW',\n",
    "        'TT','TN','TR','US','VI','UA','GB','TZ','UY','VE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state = ['AL','AK','AS','AZ','AR','CA','CO','CT','DE','DC','FL',\n",
    "        'GA','GU','HI','ID','IL','IN','IA','KS','KY','LA','ME',\n",
    "        'MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ',\n",
    "        'NM','NY','NC','ND','MP','OH','OK','OR','PA','PR','RI',\n",
    "        'SC','SD','TN','TX','UT','VT','VA','VI','WA','WV','WI','WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_info_byOrigin(country, state, dataframe):\n",
    "    \n",
    "    headers = []\n",
    "    rows_data = []\n",
    "    \n",
    "    url = f'https://www.basketball-reference.com/friv/birthplaces.fcgi?country={co}&state={st}'\n",
    "\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[1].findAll('th')]\n",
    "        rows = soup.findAll('tr')[2:]\n",
    "        rows_data = [[td.getText() for td in rows[i].findAll('td')]for i in range(len(rows))]\n",
    "    \n",
    "        last_year = 2023\n",
    "        for i in range(0, len(rows_data)):\n",
    "            rows_data[i].insert(0, last_year)\n",
    "            last_year -=1\n",
    "\n",
    "        df = pd.DataFrame(rows_data, columns = headers)\n",
    "        df['Country'] = co\n",
    "        df['State'] = st\n",
    "\n",
    "        frames=[dataframe,df]   \n",
    "        dataframe_raw = pd.concat((frames),ignore_index=True).reset_index(drop=True)\n",
    "        \n",
    "        dataframe_raw = dataframe_raw.astype({'Player':'string'})\n",
    "        dataframe_raw['Player'].str.strip()\n",
    "        \n",
    "        dataframe = dataframe_raw.loc[dataframe_raw['Player'] != '']\n",
    "                    \n",
    "        print(f'{co} , {st}')\n",
    "    except Exception as e:\n",
    "        print(f'{co} , {st}, {e} | Skipping...')\n",
    "        pass\n",
    "  \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Data\n",
      "---------------------\n",
      "AO , \n",
      "AG , \n",
      "AR , \n",
      "AU , \n",
      "AT , \n",
      "BS , \n",
      "BE , \n",
      "BA , \n",
      "BR , \n",
      "BG , \n",
      "CM , \n",
      "CA , \n",
      "CV , \n",
      "CN , \n",
      "CO , \n",
      "HR , \n",
      "CU , \n",
      "CZ , \n",
      "CD , \n",
      "DK , \n",
      "DM , \n",
      "DO , \n",
      "EG , \n",
      "EE , \n",
      "FI , \n",
      "FR , \n",
      "GF , \n",
      "GA , \n",
      "GE , \n",
      "DE , \n",
      "GH , \n",
      "GR , \n",
      "GP , \n",
      "GN , \n",
      "GY , \n",
      "HT , \n",
      "HU , \n",
      "IS , \n",
      "IE , \n",
      "IR , \n",
      "IL , \n",
      "IT , \n",
      "JM , \n",
      "JP , \n",
      "LV , \n",
      "LB , \n",
      "LT , \n",
      "LU , \n",
      "ML , \n",
      "MQ , \n",
      "MX , \n",
      "ME , \n",
      "MA , \n",
      "NL , \n",
      "NZ , \n",
      "NG , \n",
      "NO , \n",
      "PA , \n",
      "PL , \n",
      "PT , \n",
      "PR , \n",
      "KR , \n",
      "MK , \n",
      "CG , \n",
      "RO , \n",
      "RU , \n",
      "LC , \n",
      "VC , \n",
      "SN , \n",
      "RS , \n",
      "SK , \n",
      "SI , \n",
      "ZA , \n",
      "SS , \n",
      "ES , \n",
      "SD , \n",
      "SE , \n",
      "CH , \n",
      "TW , \n",
      "TT , \n",
      "TN , \n",
      "TR , \n",
      "US , AL\n",
      "US , AK\n",
      "US , AS, list index out of range | Skipping...\n",
      "US , AZ\n",
      "US , AR\n",
      "US , CA\n",
      "US , CO\n",
      "US , CT\n",
      "US , DE\n",
      "US , DC\n",
      "US , FL\n",
      "US , GA\n",
      "US , GU, list index out of range | Skipping...\n",
      "US , HI\n",
      "US , ID\n",
      "US , IL\n",
      "US , IN\n",
      "US , IA\n",
      "US , KS\n",
      "US , KY\n",
      "US , LA\n",
      "US , ME\n",
      "US , MD\n",
      "US , MA\n",
      "US , MI\n",
      "US , MN\n",
      "US , MS\n",
      "US , MO\n",
      "US , MT\n",
      "US , NE\n",
      "US , NV\n",
      "US , NH\n",
      "US , NJ\n",
      "US , NM\n",
      "US , NY\n",
      "US , NC\n",
      "US , ND\n",
      "US , MP, list index out of range | Skipping...\n",
      "US , OH\n",
      "US , OK\n",
      "US , OR\n",
      "US , PA\n",
      "US , PR, list index out of range | Skipping...\n",
      "US , RI\n",
      "US , SC\n",
      "US , SD\n",
      "US , TN\n",
      "US , TX\n",
      "US , UT\n",
      "US , VT, list index out of range | Skipping...\n",
      "US , VA\n",
      "US , VI, list index out of range | Skipping...\n",
      "US , WA\n",
      "US , WV\n",
      "US , WI\n",
      "US , WY\n",
      "VI , \n",
      "UA , \n",
      "GB , \n",
      "TZ , \n",
      "UY , \n",
      "VE , \n",
      "---------------------Data Complete---------------------\n"
     ]
    }
   ],
   "source": [
    "player_info_origin = pd.DataFrame()\n",
    "\n",
    "print(f'Retrieving Data')\n",
    "print(f'---------------------')\n",
    "    \n",
    "for co in country:\n",
    "       \n",
    "    if co == 'US':\n",
    "        for st in us_state:\n",
    "            player_info_origin = get_player_info_byOrigin(co, st, player_info_origin)\n",
    "            \n",
    "    else:\n",
    "        st = ''\n",
    "        player_info_origin = get_player_info_byOrigin(co, st, player_info_origin)\n",
    "        \n",
    "player_info_origin['Player'] = player_info_origin['Player'].map(lambda x: x.rstrip('*'))\n",
    "        \n",
    "print(f'---------------------Data Complete---------------------')\n",
    "\n",
    "\n",
    "player_info_origin.to_csv(f'{path}bkr_players_info_ByOrigin.csv', encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def get_player_info_byLetter(letter, dataframe):\n",
    "    \n",
    "    headers = []\n",
    "    rows_data = []\n",
    "    \n",
    " \n",
    "    url = f'https://www.basketball-reference.com/players/{letter}/'\n",
    "\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "        rows = soup.findAll('tr')[1:]\n",
    "        players = [[td.getText() for td in rows[i].findAll('th')][0] for i in range(len(rows))]\n",
    "        rows_data = [[td.getText() for td in rows[i].findAll('td')]for i in range(len(rows))]\n",
    "        references = [[td.get('href') for td in rows[i].findAll('a')] for i in range(len(rows))]\n",
    " \n",
    "        headers.append(\"HTML Reference\")\n",
    "   \n",
    "        for i in range(0, len(rows_data)):\n",
    "            rows_data[i].insert(0, players[i])\n",
    "            rows_data[i].append(references[i][0])\n",
    "\n",
    "        df = pd.DataFrame(rows_data, columns = headers)\n",
    "\n",
    "        frames=[dataframe,df]   \n",
    "        dataframe_raw = pd.concat((frames),ignore_index=True).reset_index(drop=True)\n",
    "        \n",
    "        dataframe_raw = dataframe_raw.astype({'Player':'string'})\n",
    "        dataframe_raw['Player'].str.strip()\n",
    "        dataframe = dataframe_raw.loc[dataframe_raw['Player'] != '']\n",
    "        \n",
    "        print(f'{letter}')\n",
    "    except Exception as e:\n",
    "        print(f'{letter}, {e} | Skipping...')\n",
    "        pass\n",
    "    return dataframe\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Data\n",
      "---------------------\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n",
      "---------------------Data Complete---------------------\n"
     ]
    }
   ],
   "source": [
    "player_info_letter = pd.DataFrame()\n",
    "\n",
    "print(f'Retrieving Data')\n",
    "print(f'---------------------')\n",
    "    \n",
    "for let in letters:\n",
    "       \n",
    "            player_info_letter = get_player_info_byLetter(let, player_info_letter)\n",
    "\n",
    "player_info_letter['Player'] = player_info_letter['Player'].map(lambda x: x.rstrip('*'))\n",
    "\n",
    "print(f'---------------------Data Complete---------------------')\n",
    "\n",
    "player_info_letter.to_csv(f'{path}bkr_players_info_ByLetter.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/players/a/abdelal01.html\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.DataFrame()\n",
    "\n",
    "headers = []\n",
    "rows_data = []\n",
    "    \n",
    " \n",
    "url = f'https://www.basketball-reference.com/players/a/'\n",
    "\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, features='lxml')\n",
    "    \n",
    "    \n",
    "try:\n",
    "    headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "    players = [[td.getText() for td in rows[i].findAll('th')][0] for i in range(len(rows))]\n",
    "    reference = [[td.get('href') for td in rows[i].findAll('a')] for i in range(len(rows))]\n",
    "    rows_data = [[td.getText() for td in rows[i].findAll('td')]for i in range(len(rows))]\n",
    "    \n",
    "    for i in range(0, len(rows_data)):\n",
    "        rows_data[i].insert(0, players[i])\n",
    "\n",
    "    df = pd.DataFrame(rows_data, columns = headers)\n",
    "\n",
    "    frames=[test_data,df]   \n",
    "    test_data_raw = pd.concat((frames),ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "    test_data_raw = test_data_raw.astype({'Player':'string'})\n",
    "    test_data_raw['Player'].str.strip()\n",
    "        \n",
    "    test_data = test_data_raw.loc[test_data_raw['Player'] != '']\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "\n",
    "print(reference[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
